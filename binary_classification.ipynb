{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleteme\n",
    "# from pandas.tools.plotting import table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silas/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/silas/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import timeit\n",
    "import csv\n",
    "import os\n",
    "import string\n",
    "import textblob\n",
    "import requests\n",
    "import io\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "from importlib import reload\n",
    "# reload(text_processing)\n",
    "\n",
    "\n",
    "# nlp = spacy.load('en') # loading the language model \n",
    "#data = pd.read_feather('data/preprocessed_data') # reading a pandas dataframe which is stored as a feather file\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# sns.set_context('poster')\n",
    "# sns.set_color_codes()\n",
    "full_path_data_store = '/home/silas/final_project/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets as needed - care for memory overflow\n",
    "\n",
    "# df_names = ['climate','climate_alt','eu','spam','newsgroups','reuters','bbc','science']\n",
    "\n",
    "df_names=['climate_science','eu_science']\n",
    "\n",
    "def load_df_datasets(df_lst):\n",
    "    \"\"\"\n",
    "    Loads data from local data stored as pickle file\n",
    "    Args\n",
    "        df_lst: a list of dataframe names - see data_loader.ipynb\n",
    "    Returns\n",
    "        df_dataset: a dataframe of datasets\n",
    "    \"\"\"\n",
    "    df_datasets={}\n",
    "    for df_name in df_lst:\n",
    "        \n",
    "        with open('Data/{}.pkl'.format(df_name), 'rb') as handle:\n",
    "            df_datasets[df_name] = pickle.load(handle)\n",
    "    \n",
    "    return df_datasets\n",
    "\n",
    "\n",
    "df_datasets = load_df_datasets(df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs\n",
    "\n",
    "nomenclature for labeling runs\n",
    "\n",
    "> binary ('bin')\n",
    "   - toy datasets (e.g. 'bin_spam')\n",
    "   - climate merged ('bin_mgd')\n",
    "       + 'science' (e.g. 'bin_mgd_science')\n",
    "\n",
    "> multi-class as binary ('mult_bin') \\ use binarization cell below\n",
    "   - toy datasets (e.g. 'mult_bin_bbc')\n",
    "   - climate_merged ('mult_bin_mgd')\n",
    "       + 'science' ('mult_bin_mgd_science')\n",
    "\n",
    "> multi-class as multi-class ('mult_mult')\n",
    "   - toy datasets (e.g. 'mult_mult_bbc')\n",
    "   - climate_merged ('mult_mult_mgd')\n",
    "       + 'science' ('mult_mult_mgd_science')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climate_science', 'eu_science']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ready available datasets\n",
    "list(df_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for processed data, enter 1 1\n"
     ]
    }
   ],
   "source": [
    "#select processed or unprocessed text data\n",
    "processed=input('for processed data, enter 1 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provide title of run: final\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'Output/final_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-abc445f5c1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_title\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make dir for saves - hash if already created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrun_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# enter dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_name_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'provide primary dataset name: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'Output/final_1'"
     ]
    }
   ],
   "source": [
    "# enter run title here with '_' connecting words\n",
    "run_title = input('provide title of run: ')+'_'\n",
    "run_title = run_title+processed\n",
    "# make dir for saves - hash if already created\n",
    "os.mkdir('Output/'+run_title)\n",
    "# enter dataset\n",
    "df_name_=input('provide primary dataset name: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split single dataframe into processed and unprocessed text and labels\n",
    "\n",
    "def pre_split_data(df):\n",
    "    texts = df.texts\n",
    "    labels = df.labels\n",
    "    processed_texts = df.processed_text\n",
    "    return  texts,labels,processed_texts\n",
    "\n",
    "texts,labels,processed_texts=pre_split_data(df_datasets[df_name_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and label encode the target variable for raw and processed datasets\n",
    "\n",
    "def split_single():\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits a single dataframe into train and test, text and labels\n",
    "    \n",
    "    Args\n",
    "        texts: either processed_texts or texts (unprocessed)\n",
    "    Returns\n",
    "        split and encoded arrays for experiments\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "# PROCESSED: preprocessed text, split the dataset into training and validation datasets \n",
    "    if processed==\"1\":\n",
    "        print('splitting and encoding processed data...')\n",
    "        train_x, valid_x, train_y_text_label, valid_y_text_label = train_test_split(processed_texts, labels)\n",
    "\n",
    "# UNPROCESSED: raw text, split the dataset into training and validation datasets\n",
    "    else: \n",
    "        print('splitting and encoding unprocessed data...')\n",
    "        train_x, valid_x, train_y_text_label, valid_y_text_label = train_test_split(texts, labels)\n",
    "    \n",
    "\n",
    "    \n",
    "    return  train_x, valid_x, train_y_text_label, valid_y_text_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_climate_eu(df_train_name,df_val_name):\n",
    "    \"\"\"\n",
    "    Splits a climate_bbc and eu_bbc dataframe into train (climate_bbc) and test (eu_bbc), text and labels\n",
    "    \n",
    "    Args\n",
    "        texts: either processed_texts or texts (unprocessed)\n",
    "    Returns\n",
    "        split and encoded arrays for experiments\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    labels_climate_bbc=df_datasets[df_train_name]['labels']\n",
    "    labels_eu_bbc=df_datasets[df_val_name]['labels']\n",
    "    \n",
    "    if processed=='1':\n",
    "        \n",
    "        \n",
    "        print('encoding processed data...')\n",
    "        climate_bbc_processed_texts=df_datasets[df_train_name]['processed_text']\n",
    "        eu_bbc_processed_texts=df_datasets[df_val_name]['processed_text']\n",
    "        train_x, valid_x_, train_y_text_label, valid_y_text_label_ = train_test_split(climate_bbc_processed_texts, labels_climate_bbc)\n",
    "        train_x_, valid_x, train_y_text_label_, valid_y_text_label = train_test_split(eu_bbc_processed_texts, labels_eu_bbc)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('encoding unprocessed data...')\n",
    "        climate_bbc_texts=df_datasets[df_train_name]['texts']\n",
    "        eu_bbc_texts=df_datasets[df_val_name]['texts']\n",
    "        train_x, valid_x_, train_y_text_label, valid_y_text_label_ = train_test_split(climate_bbc_texts, labels_climate_bbc)\n",
    "        train_x_, valid_x, train_y_text_label_, valid_y_text_label = train_test_split(eu_bbc_texts, labels_eu_bbc)\n",
    "    \n",
    "\n",
    "    return train_x, valid_x, train_y_text_label, valid_y_text_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select data: enter \"1\" for case {climate:train and eu:test} 1\n",
      "enter train df name climate_science\n",
      "enter val df name eu_science\n"
     ]
    }
   ],
   "source": [
    "single=input('select data: enter \"1\" for case {climate:train and eu:test} ')\n",
    "\n",
    "if single==\"1\":\n",
    "    df_train_name=input('enter train df name ')\n",
    "    df_val_name=input('enter val df name ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting climate/eu datasets...\n",
      "encoding processed data...\n"
     ]
    }
   ],
   "source": [
    "if single!='1':\n",
    "    print('splitting single dataset...')\n",
    "    train_x, valid_x, train_y_text_label, valid_y_text_label=split_single()\n",
    "else:\n",
    "    print('splitting climate/eu datasets...')\n",
    "    train_x, valid_x, train_y_text_label, valid_y_text_label=split_climate_eu(df_train_name,df_val_name)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y_text_label)\n",
    "valid_y = encoder.fit_transform(valid_y_text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check classes:  encoder.classes_\n",
    "# get back original class labels: encoder.inverse_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of recording run times for models\n",
    "time_keeper={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize data labels\n",
    "- binary classification --> takes one category (ex: label '1') and makes '1' all others '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run if binary experiment\n",
    "\n",
    "binary=input('enter 1 to binarize ')\n",
    "\n",
    "def binarize(train_y,valid_y,label_id=1):\n",
    "    \n",
    "    train_y = np.array((pd.DataFrame({'t_label':train_y}).t_label == label_id).astype('int'))\n",
    "    valid_y = np.array((pd.DataFrame({'t_label':valid_y}).t_label == label_id).astype('int'))\n",
    "    \n",
    "    return train_y,valid_y\n",
    "\n",
    "if binary=='1':\n",
    "    print('binarizing data...')\n",
    "    train_y,valid_y=binarize(train_y,valid_y)\n",
    "    print('finished')\n",
    "    # class counts for binarized df\n",
    "    print(\"valid: positive class {}\\nnegative class {}\".format(len(valid_y[valid_y==1]),len(valid_y[valid_y==0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "[reference](#https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options\n",
    "- [Count & TFIDF vectorization](#vectorizing)\n",
    "- [NLP feature extraction](#nlp)\n",
    "- [LDA topic modeling](#topic_modeling)\n",
    "- [Word embeddings](#embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vectorizing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count & TFIDF Vectorizing: \n",
    "[reference](#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- Analyzer, \"word\" or \"char\"\n",
    "- Strip out stop words (ex: \"english\").\n",
    "- Filter out terms that occur in more than half of the docs (ex: max_df=0.5)\n",
    "- Filter out terms that occur in only one document (min_df=2).\n",
    "- Select the N most frequently occuring words in the corpus.\n",
    "- default for tfidf - normalize the vector (L2 norm of 1.0) to normalize the effect of document length on the tf-idf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params take form of (analyzer, token pattern, stop_words)\n",
    "\n",
    "def run_vectorizer(train_x_,valid_x_, model, params):\n",
    "\n",
    "    # create a vectorizer object \n",
    "    if model == CountVectorizer:\n",
    "        print('count vectorizing...')\n",
    "        vect = model(analyzer=params[0], token_pattern=params[1], stop_words=params[2], \n",
    "                     lowercase=params[3], ngram_range=params[4])\n",
    "    \n",
    "    else:\n",
    "        print('tfidf vectorizing...')\n",
    "        vect = model(model(analyzer=params[0], max_df=params[1], min_df=params[2], max_features=params[3], \n",
    "          stop_words=params[4], use_idf=params[5]), token_pattern=params[6], ngram_range=params[7])\n",
    "    \n",
    "    if processed=='1':\n",
    "        print('fitting processed texts')\n",
    "        vect.fit(processed_texts)\n",
    "        \n",
    "    else:\n",
    "        vect.fit(texts)\n",
    "\n",
    "    # transform the training and validation data using count vectorizer objectea\n",
    "    xtrain_ =  vect.transform(train_x_)\n",
    "    xvalid_ =  vect.transform(valid_x_)\n",
    "    \n",
    "    return xtrain_, xvalid_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# count vectorizer params\n",
    "model_count = CountVectorizer\n",
    "\n",
    "params_count1 = ('word', r'\\w{1,}', 'english', True, (1,1))\n",
    "params_count2 = ('char', r'\\w{1,}', 'english', True, (1,1))\n",
    "params_count3 = ('word', r'\\w{1,}', 'english', True, (2,3))\n",
    "params_count4 = ('char', r'\\w{1,}', 'english', True, (2,3))\n",
    "\n",
    "print('processing...')\n",
    "xtrain_count,xvalid_count= run_vectorizer(train_x,valid_x, model_count, params_count1)\n",
    "xtrain_count_char,xvalid_count_char = run_vectorizer(train_x,valid_x, model_count, params_count2)\n",
    "xtrain_count_ngram,xvalid_count_ngram = run_vectorizer(train_x,valid_x, model_count, params_count3)\n",
    "xtrain_count_ngram_chars,xvalid_count_ngram_chars = run_vectorizer(train_x,valid_x, model_count, params_count4)\n",
    "\n",
    "# code you want to evaluate\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['count_vectorization'] = elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectors\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select processed or unprocessed text data for tfidf vectorization\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# tfidf vectorizer params\n",
    "\n",
    "model_tfidf = TfidfVectorizer\n",
    "\n",
    "params_tfidf1 = ('word',0.9,2,5000,'english',True, r'\\w{1,}', (1,1))\n",
    "params_tfidf2 = ('char',0.9,2,5000,'english',True, r'\\w{1,}', (1,1))\n",
    "params_tfidf3 = ('word',0.9,2,5000,'english',True, r'\\w{1,}', (2,3))\n",
    "params_tfidf4 = ('char',0.9,2,5000,'english',True, r'\\w{1,}', (2,3))\n",
    "\n",
    "print('processing...')\n",
    "xtrain_tfidf,xvalid_tfidf= run_vectorizer(train_x,valid_x, model_tfidf, params_tfidf1)\n",
    "xtrain_tfidf_char,xvalid_tfidf_char = run_vectorizer(train_x,valid_x, model_tfidf, params_tfidf2)\n",
    "xtrain_tfidf_ngram,xvalid_tfidf_ngram = run_vectorizer(train_x,valid_x, model_tfidf, params_tfidf3)\n",
    "xtrain_tfidf_ngram_chars,xvalid_tfidf_ngram_chars = run_vectorizer(train_x,valid_x, model_tfidf, params_tfidf4)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['tfidf_vectorization'] = elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[jump to models](#models)\n",
    "<a id='nlp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text / NLP based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NLP_features(texts, normed_=True):\n",
    "\n",
    "    trainDF=pd.DataFrame()\n",
    "    trainDF['char_count'] = texts.apply(len)\n",
    "    trainDF['word_count'] = texts.apply(lambda x: len(x.split()))\n",
    "    trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "    trainDF['punctuation_count'] = texts.apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "    trainDF['title_word_count'] = texts.apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "    trainDF['upper_case_word_count'] = texts.apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "    \n",
    "    pos_family = {\n",
    "        'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "        'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "        'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "        'adj' :  ['JJ','JJR','JJS'],\n",
    "        'adv' : ['RB','RBR','RBS','WRB']\n",
    "    }\n",
    "    \n",
    "    # function to check and get the part of speech tag count of a words in a given sentence\n",
    "    def check_pos_tag(x, flag):\n",
    "        cnt = 0\n",
    "        try:\n",
    "            wiki = textblob.TextBlob(x)\n",
    "            for tup in wiki.tags:\n",
    "                ppo = list(tup)[1]\n",
    "                if ppo in pos_family[flag]:\n",
    "                    cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "        return cnt\n",
    "    \n",
    "    trainDF['noun_count'] = texts.apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "    trainDF['verb_count'] = texts.apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "    trainDF['adj_count'] = texts.apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "    trainDF['adv_count'] = texts.apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "    trainDF['pron_count'] = texts.apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "    \n",
    "    if normed_:\n",
    "        \n",
    "        x = trainDF.values #returns a numpy array\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        trainDF_normed = pd.DataFrame(x_scaled,columns=trainDF.columns)\n",
    "        trainDF_normed.to_pickle('Other/{}_nlp_features_normed'.format(run_title))\n",
    "        \n",
    "        return trainDF_normed\n",
    "    \n",
    "    time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "    trainDF.to_pickle('Output/{}/{}_nlp_features_{}'.format(run_title,run_title, df_name_))\n",
    "    \n",
    "    return trainDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_features = get_NLP_features(train_x,normed_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Model\n",
    "\n",
    "-  https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='topic_modeling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dictionary(dictionary, n=10):\n",
    "    '''\n",
    "    Returns: the first n words from dictionary \n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    for k, v in dictionary.iteritems():\n",
    "        print(k, v)\n",
    "        count += 1\n",
    "        if count > n:\n",
    "            break\n",
    "            \n",
    "# list_dictionary(dictionary, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_corpus_doc(corpus,doc_to_insp):\n",
    "    \"\"\"\n",
    "    Inspect a doc in the corpus for word frequencies\n",
    "    Args\n",
    "        corpus: corpus\n",
    "        doc_to_insp: int value to show n docs  \n",
    "    Return\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_insp = corpus[doc_to_insp]\n",
    "    for i in range(len(doc_insp)):\n",
    "        print(\"Word {} (\\\"{}\\\") score {}\".format(doc_insp[i][0],dictionary[doc_insp[i][0]],doc_insp[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print topics from lda_model\n",
    "def get_topics(model):\n",
    "    for idx, topic in model.print_topics(-1):\n",
    "        print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "# get_topics(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect where doc in corpus would be classified/assigned topic probability\n",
    "def lda_in_doc_classification(model, corpus, doc_num):\n",
    "    for index, score in sorted(model[corpus[doc_num]], key=lambda tup: -1*tup[1]):\n",
    "        print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, model.print_topic(index, 10)))\n",
    "# lda_in_doc_classification(lda_model, bow_corpus, 20)\n",
    "# lda_in_doc_classification(lda_model_tfidf, bow_corpus, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_out_doc_classification(unseen_document):\n",
    "    \"\"\"\n",
    "    Takes a list of a single doc string\n",
    "    example: unseen_document = ['The night love tomorrow']\n",
    "    Args\n",
    "        unseen_document: single list of tokens\n",
    "    \"\"\"\n",
    "    from text_processing import preprocess_spacy\n",
    "    text = preprocess_spacy(pd.DataFrame({'texts': unseen_document})).str.split()[0]\n",
    "    bow_vector = dictionary.doc2bow(text)\n",
    "    for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "        print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary, bow corpus, and tfidf corpus (using bow corpus)\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel,LdaMulticore\n",
    "dictionary = Dictionary(processed_texts.str.split())\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.1, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in train_xp.str.split()]\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_corpus_doc(bow_corpus,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_corpus_doc(corpus_tfidf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using Bag of Words\n",
    "lda_model = LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using TF-IDF\n",
    "lda_model_tfidf = LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topics(lda_model_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.show_topics(10)\n",
    "# lda_model_tfidf.get_topics().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document=['Climate policy jurisdiction based reform']\n",
    "lda_out_doc_classification(unseen_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA TFIDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "query_doc = [w.lower() for w in word_tokenize(\"here is good place to stay.\")]\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tfidf[query_doc_bow]\n",
    "print(query_doc_tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "# https://www.oreilly.com/learning/how-do-i-compare-document-similarity-using-python\n",
    "# TFIDF = TfidfModel(corpus)\n",
    "from gensim.similarities import Similarity\n",
    "sims = Similarity('temp' , corpus_tfidf, num_features = len(dictionary))\n",
    "sim_output= sims[query_doc_tf_idf]\n",
    "sim_output = sorted(enumerate(sim_output), key=lambda item: -item[1])\n",
    "        \n",
    "# inspect_corpus(corpus,1704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sim_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "q_doc_TFIDF = tfidf[q_doc]\n",
    "temp_lst=[]\n",
    "for idx,i in enumerate(sims[q_doc_TFIDF]):\n",
    "    if i != 0.:\n",
    "        temp_lst.append((idx,i))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "<a id='inspect_train_models'></a>\n",
    "[inspect_vectorizing](#vectorizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Models\n",
    "- run all functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_x_, train_y_, valid_x_, valid_y_, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    print('Running model...')\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    if is_neural_net:\n",
    "        result = classifier.fit(train_x_, train_y_, epochs=3, validation_split=0.2)\n",
    "        y_predicted = classifier.predict(valid_x_)\n",
    "        y_predicted = (y_predicted > .12) # y_predicted.argmax(axis=-1)\n",
    "        \n",
    "    else:\n",
    "        result = classifier.fit(train_x_, train_y_)\n",
    "        # predict the labels on validation dataset\n",
    "        y_predicted = classifier.predict(valid_x_)\n",
    "    \n",
    "    # record results here\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    plot_confusion_matrix(valid_y_, y_predicted)\n",
    "    print('Fetching report...')\n",
    "    report = classification_report(valid_y_, y_predicted) \n",
    "    lines = report.split('\\n')\n",
    "    \n",
    "    report_data = []\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[1]\n",
    "        row['precision'] = float(row_data[2])\n",
    "        row['recall'] = float(row_data[3])\n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['support'] = int(row_data[5])\n",
    "        row['time_secs'] = elapsed\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame(report_data)\n",
    "    \n",
    "    if is_neural_net: \n",
    "        fig, axs = plt.subplots(1,1)\n",
    "        plot_loss(result)\n",
    "        plot_accuracy(result)\n",
    "        \n",
    "    \n",
    "    return dataframe,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(result,savefig_=True):\n",
    "    plt.plot(result.history['acc'])\n",
    "    plt.plot(result.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    if savefig_:\n",
    "        time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "        plt.savefig('Output/{}/accuracy_plot_{}_{}.png'.format(run_title,run_title,time_))\n",
    "        \n",
    "        \n",
    "def plot_loss(result,savefig_=True):\n",
    "    plt.plot(result.history['loss'])\n",
    "    plt.plot(result.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    if savefig_:\n",
    "        time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "        plt.savefig('Output/{}/loss_plot_{}_{}.png'.format(run_title,run_title,time_))\n",
    "\n",
    "# summarize result for accuracy\n",
    "#plot_accuracy(result)\n",
    "\n",
    "# summarize result for loss\n",
    "#plot_loss(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(valid_y_, y_predicted, savefig_=True):\n",
    "    cm = confusion_matrix(valid_y_, y_predicted)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    fig = plt.figure(figsize=(4,3))\n",
    "    heatmap = sns.heatmap(df_cm,annot=True,cmap='Blues', fmt='g', cbar=False)\n",
    "    heatmap.set(xlabel='{}'.format(run_title))\n",
    "    if savefig_:\n",
    "        time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "        plt.savefig('Output/{}/confusion_matrix_{}_{}.png'.format(run_title,run_title,time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_out(report,df_title):\n",
    "    '''\n",
    "    Builds a dataframe from a classification report\n",
    "    '''\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    timex = time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "    dataframe.to_csv('Output/{}/classification_report_{}_{}.csv'.format(run_title,df_title,timex), index = False)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#report = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(df):\n",
    "    \"\"\"\n",
    "    Saves dataframe as .png file \n",
    "    \"\"\"\n",
    "    ax = plt.subplot(111, frame_on=False) \n",
    "    ax.xaxis.set_visible(False)  \n",
    "    ax.yaxis.set_visible(False)  \n",
    "    pd.tools.plotting.table(ax, df,header_columns=0, col_width=2.0)  \n",
    "    plt.savefig('Output/{}/{}_{}.png'.format(run_title,run_title, time_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[jump_to_NNs](#NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "score1,result1 = train_model(MultinomialNB(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "\n",
    "score2,result2 = train_model(MultinomialNB(), xtrain_count_char, train_y, xvalid_count_char, valid_y)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "score3,result3 = train_model(MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "score4,result4 = train_model(MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y)\n",
    "#print(\"NB, N-Gram Vectors: \", score,result)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "score5,result5 = train_model(MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y)\n",
    "#print(\"NB, CharLevel Vectors: \", score,result)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['NB_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"NB, Count Vectors:\",\"NB, Count Vectors Char: \",\"NB, WordLevel TF-IDF: \",\n",
    "\"NB, N-Gram Vectors: \",\"NB, CharLevel Vectors: \"]\n",
    "df_nb = score1.append(score2).append(score3).append(score4).append(score5)\n",
    "names = list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_nb['class']))) for x in names))\n",
    "df_nb[' ']=names\n",
    "df_nb = df_nb.set_index(' ')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_nb.to_csv('Output/{}/nb_classification_report_{}_{}.csv'.format(run_title,run_title,time_), index = False)\n",
    "df_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "score1, result1 = train_model(KNeighborsClassifier(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "# print(\"KNN, Count Vectors: \", score, result)\n",
    "\n",
    "score2, result2 = train_model(KNeighborsClassifier(), xtrain_count_char, train_y, xvalid_count_char, valid_y)\n",
    "# print(\"KNN, Count Vectors Char: \", score, result)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "score3, result3 = train_model(KNeighborsClassifier(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\n",
    "# print(\"KNN, WordLevel TF-IDF: \", score, result)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "score4, result4 = train_model(KNeighborsClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y)\n",
    "# print(\"KNN, N-Gram Vectors: \", score, result)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "score5, result5 = train_model(KNeighborsClassifier(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y)\n",
    "#print(\"KNN, CharLevel Vectors: \", score, result)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['KNN_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_nb['class']))) for x in names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"KNN, Count Vectors:\",\"KNN, Count Vectors Char: \",\"KNN, WordLevel TF-IDF: \",\"KNN, N-Gram Vectors: \",\"KNN, CharLevel Vectors: \"]\n",
    "df_knn = score1.append(score2).append(score3).append(score4).append(score5)\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_knn['class']))) for x in names))\n",
    "df_knn['Model_Vec']=names\n",
    "df_knn = df_knn.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_knn.to_csv('Output/{}/knn_classification_report_{}_knn_{}.csv'.format(run_title,run_title,time_))\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM N-Gram Chars on TF IDF Vectors\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "score1,result1 = train_model(SVC(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "# print(\"SVM, Count Vectors: \", score,result)\n",
    "\n",
    "score2,result2 = train_model(SVC(), xtrain_count_char, train_y, xvalid_count_char, valid_y)\n",
    "# print(\"SVM, Count Vectors Char: \", score,result)\n",
    "\n",
    "# SVM on Word Level TF IDF Vectors\n",
    "score3,result3 = train_model(SVC(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\n",
    "# print(\"SVM, WordLevel TF-IDF: \", score,result)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "score4,result4 = train_model(SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y)\n",
    "# print(\"SVM, N-Gram Vectors: \", score,result)\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "score5,result5 = train_model(SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y)\n",
    "#print(\"SVM, CharLevel Vectors: \", score,result)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['SVM_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"SVM, Count Vectors:\",\"SVM, Count Vectors Char: \",\n",
    "\"SVM, WordLevel TF-IDF: \",\"SVM, N-Gram Vectors: \",\"SVM, CharLevel Vectors: \"]\n",
    "df_svm = score1.append(score2).append(score3).append(score4).append(score5)\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_knn['class']))) for x in names))\n",
    "df_svm['Model_Vec']=names\n",
    "df_svm = df_svm.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_svm.to_csv('Output/{}/svm_classification_report_{}_svm_{}.csv'.format(run_title,run_title, time_))\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "#\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(min_df=3, max_df=0.95)),\n",
    "        ('clf', LinearSVC(C=1000)),\n",
    "    ])\n",
    "\n",
    "# TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "# more useful.\n",
    "# Fit the pipeline on the training set using grid search for the parameters\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "}\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, cv=kfolds,verbose=1)\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# TASK: print the mean and std for each candidate along with the parameter\n",
    "# settings for all the candidates exlored by grid search.\n",
    "n_candidates = len(grid_search.cv_results_['params'])\n",
    "for i in range(n_candidates):\n",
    "    print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n",
    "             % (grid_search.cv_results_['params'][i],\n",
    "                grid_search.cv_results_['mean_test_score'][i],\n",
    "                grid_search.cv_results_['std_test_score'][i]))\n",
    "\n",
    "y_predicted = grid_search.predict(valid_x)\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(valid_y, y_predicted)\n",
    "\n",
    "# Print and plot the confusion matrix\n",
    "plot_confusion_matrix(valid_y, y_predicted)\n",
    "\n",
    "df_svc = classification_report_out(report,run_title)\n",
    "\n",
    "# df_svc['Model_Vec']=names\n",
    "# df_svc = df_svm.set_index('Model_Vec')\n",
    "# df_svc.to_csv('classification_report_climate_reuters_svc.csv')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['SVC_ex.2.grid_{}'.format(run_title)]=elapsed\n",
    "\n",
    "df_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_stopwords = set(stopwords.words(\"english\")) \n",
    "from text_processing import tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenizer,\n",
    "    lowercase = True,\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words = stopwords.words('english'))\n",
    "\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "pipeline_svm = make_pipeline(vectorizer, \n",
    "                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "\n",
    "grid_svm = GridSearchCV(pipeline_svm,\n",
    "                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n",
    "                    cv = kfolds,\n",
    "                    scoring=\"roc_auc\",\n",
    "                    verbose=1,   \n",
    "                    n_jobs=-1) \n",
    "\n",
    "grid_svm.fit(train_x, train_y)\n",
    "grid_svm.score(valid_x, valid_y)\n",
    "\n",
    "\n",
    "predictions_svm_ = grid_svm.predict(valid_x)\n",
    "cm = confusion_matrix(valid_y, predictions_svm_)\n",
    "report=classification_report(valid_y,predictions_svm_)\n",
    "plot_confusion_matrix(valid_y, predictions_svm_)\n",
    "df_svm = classification_report_out(report,run_title)\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect errors\n",
    "# error_df = pd.DataFrame({'val_text':valid_x, 'val_true':valid_y, 'val_pred':predictions_svm_})\n",
    "# error_df[(error_df['val_pred']!=error_df['val_true'])].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Logistic Regression on Count Vectors\n",
    "score1, result1 = train_model(LogisticRegression(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "#print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Logistic Regression on Word Level TF IDF Vectors\n",
    "score2, result2 = train_model(LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\n",
    "#print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Logistic Regression on Ngram Level TF IDF Vectors\n",
    "score3, result3 = train_model(LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y)\n",
    "#print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Logistic Regression on Character Level TF IDF Vectors\n",
    "score4, result4 = train_model(LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y)\n",
    "#print(\"LR, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['Logistic_Regression_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"LRM, Count Vectors:\", \"LRM, WordLevel TF-IDF: \",\"LRM, N-Gram Vectors: \",\"LRM, CharLevel Vectors: \"]\n",
    "df_LRM = score1.append(score2).append(score3).append(score4)\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_LRM['class']))) for x in names))\n",
    "df_LRM['Model_Vec']=names\n",
    "df_LRM = df_LRM.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_LRM.to_csv('Output/{}/LRM_classification_report_{}_{}.csv'.format(run_title,run_title,time_))\n",
    "df_LRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Random Forest Classifier on Count Vectors\n",
    "score1, result1 = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "#print(\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# Random Forest Classifier on Word Level TF IDF Vectors\n",
    "score2, result2 = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\n",
    "#print(\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Random Forest Classifier on Ngram Level TF IDF Vectors\n",
    "score3, result3 = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y)\n",
    "#print(\"RF, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Random Forest Classifier on Character Level TF IDF Vectors\n",
    "score4, result4 = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y)\n",
    "#print(\"RF, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['Random_Forest_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"RF, Count Vectors:\",\"RF, WordLevel TF-IDF: \",\"RF, N-Gram Vectors: \",\"RF, CharLevel Vectors: \"]\n",
    "df_RF = score1.append(score2).append(score3).append(score4)\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_RF['class']))) for x in names))\n",
    "df_RF['Model_Vec']=names\n",
    "df_RF = df_RF.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_RF.to_csv('Output/{}/RF_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "df_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tk=pd.DataFrame.from_dict(time_keeper, orient='index', columns=['total_test_time_secs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tk.to_csv('Output/{}/{}_merged_run_times_unprocessed.csv'.format(run_title,run_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='NNs'></a>\n",
    "[inspect_train_models](#inspect_train_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "def create_model_architecture(input_size):\n",
    "    # create input layer \n",
    "    input_layer = layers.Input((input_size, ), sparse=True)\n",
    "    \n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier \n",
    "\n",
    "#classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "# score, result1 = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram,valid_y, is_neural_net=True)\n",
    "\n",
    "# Neural net on Count Vectors\n",
    "classifier = create_model_architecture(xtrain_count.shape[1])\n",
    "score1, result1 = train_model(classifier, xtrain_count, train_y, xvalid_count, valid_y, is_neural_net=True)\n",
    "\n",
    "\n",
    "# Neural net on Word Level TF IDF Vectors\n",
    "classifier = create_model_architecture(xtrain_tfidf.shape[1])\n",
    "score2, result2 = train_model(classifier, xtrain_tfidf, train_y, xvalid_tfidf, valid_y, is_neural_net=True)\n",
    "\n",
    "\n",
    "# Neural net on Ngram Level TF IDF Vectors\n",
    "classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "score3, result3 = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y, is_neural_net=True)\n",
    "\n",
    "\n",
    "# Neural net on Character Level TF IDF Vectors\n",
    "classifier = create_model_architecture(xtrain_tfidf_ngram_chars.shape[1])\n",
    "score4, result4 = train_model(classifier, xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, valid_y, is_neural_net=True)\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "time_keeper['Neural_Net_{}'.format(run_title)]=elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save joined results\n",
    "names = [\"NN, Count Vectors:\",\"NN, WordLevel TF-IDF: \",\"NN, N-Gram Vectors: \",\"NN, CharLevel Vectors: \"]\n",
    "df_NN = score1.append(score2).append(score3).append(score4)\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(df_NN['class']))) for x in names))\n",
    "df_NN['Model_Vec']=names\n",
    "df_NN = df_NN.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_NN.to_csv('Output/{}/NN_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "# save_table(df_NN)\n",
    "df_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embeddings'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('../Data/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer in keras\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(texts)\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_cnn()\n",
    "score1,result1 = train_model(classifier, train_seq_x, train_y, valid_seq_x, valid_y, is_neural_net=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"CNN\"]\n",
    "df_CNN = score1\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(valid_y))) for x in names))\n",
    "    \n",
    "df_CNN['Model_Vec']=names\n",
    "df_CNN=df_CNN.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_CNN.to_csv('Output/{}/CNN_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "df_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_lstm():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_lstm()\n",
    "score1, result = train_model(classifier, train_seq_x, train_y, valid_seq_x, valid_y, is_neural_net=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"LSTM\"]\n",
    "df_LSTM = score1\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(valid_y))) for x in names))\n",
    "    \n",
    "df_LSTM['Model_Vec']=names\n",
    "df_LSTM=df_LSTM.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_LSTM.to_csv('Output/{}/{}_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "df_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirectional_rnn():\n",
    "# Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_bidirectional_rnn()\n",
    "score1, result = train_model(classifier, train_seq_x, train_y, valid_seq_x, valid_y, is_neural_net=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RNN_BD\"]\n",
    "df_RNN_BD = score1\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(valid_y))) for x in names))\n",
    "df_RNN_BD['Model_Vec']=names\n",
    "df_RNN_BD=df_RNN_BD.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_RNN_BD.to_csv('Output/{}/{}_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "df_RNN_BD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # Add the recurrent layer\n",
    "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rcnn()\n",
    "score1,result = train_model(classifier, train_seq_x, train_y, valid_seq_x,valid_y, is_neural_net=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RCNN\"]\n",
    "df_RCNN = score1\n",
    "names=list(itertools.chain.from_iterable(itertools.repeat(x, len(set(valid_y))) for x in names))\n",
    "df_RCNN['Model_Vec']=names\n",
    "df_RCNN=df_RCNN.set_index('Model_Vec')\n",
    "time_=time.strftime(\"%a_%d_%b_%Y_%H:%M:%S\", time.gmtime())\n",
    "df_RCNN.to_csv('Output/{}/{}_classification_report_{}.csv'.format(run_title,run_title,time_))\n",
    "df_RCNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
